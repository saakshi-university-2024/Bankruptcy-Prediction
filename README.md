# Bankruptcy Prediction
Our SAS EM Database training utilizes an ensemble model that combines two powerful machine learning techniques: Gradient Boosting Tree and Neural Network. This approach leverages the strengths of both algorithms to enhance predictive performance and model robustness. Gradient Boosting Tree The Gradient Boosting Tree model is configured with the following parameters: - Number of trees (N): 355 - Learning rate: 0.1 - Maximum depth: 5 This configuration allows for a balanced trade-off between model complexity and generalization ability. The relatively high number of trees (355) provides ample opportunity for the model to capture intricate patterns in the data, while the modest learning rate (0.1) helps prevent overfitting. The maximum depth of 5 limits the complexity of individual trees, further guarding against overfitting while maintaining good predictive power. Neural Network The Neural Network component of our ensemble is set up as follows: - Hidden units: 3 - Maximum iterations: 999 
This architecture features a compact hidden layer with 3 units, which allows the network to model non-linear relationships in the data without excessive complexity. The iteration limit of 999 enables the model to train extensively, with an automatic selection mechanism to choose the best-performing iteration, optimizing the balance between fitting the training data and maintaining generalizability. Ensemble Approach By combining these two models, we create a robust ensemble that capitalizes on the strengths of both algorithms. The Gradient Boosting Tree excels at handling complex feature interactions and non-linear relationships, while the Neural Network contributes its ability to capture intricate patterns and generalize well to unseen data. Training and Validation Strategy Notably, our model utilizes 100% of the available training data, as this approach yielded the best results in our experiments. This full data utilization allows the models to learn from the entire spectrum of available information, potentially leading to more comprehensive and accurate predictions. To validate our model's performance, we can use a separate validation dataset. This dataset should be independent of the training data to provide an unbiased assessment of the model's generalization capabilities. By applying our trained ensemble model to this validation set, we can evaluate its performance on unseen data and fine-tune our approach if necessary. Performance Achievement It's worth noting that our ensemble model has demonstrated exceptional performance, achieving a remarkable **95% accuracy on the public Kaggle leaderboard**. 
This high accuracy score underscores the effectiveness of our modeling approach and parameter tuning, indicating strong predictive capabilities across a diverse range of data points. This ensemble model structure, combined with our carefully tuned parameters, full data utilization strategy, and validated performance, forms the core of our highly effective predictive modeling approach for the SAS EM Database.
